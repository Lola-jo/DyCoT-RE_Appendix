% [1]
@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}

% [2]
@book{russell2016artificial,
  title={Artificial intelligence: A modern approach},
  author={Russell, Stuart J and Norvig, Peter},
  year={2016},
  publisher={Pearson}
}

% [3]
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{arora2021survey,
  title={A survey of inverse reinforcement learning: Challenges, methods and progress},
  author={Arora, Saurabh and Doshi, Prashant},
  journal={Artificial Intelligence},
  volume={297},
  pages={103500},
  year={2021},
  publisher={Elsevier}
}

% [4]
@article{baker2019emergent,
  title={Emergent tool use from multi-agent autocurricula},
  author={Baker, Bowen and Kanitscheider, Ingmar and Markov, Todor and Wu, Yi and Powell, Glenn and McGrew, Bob and Mordatch, Igor},
  journal={arXiv preprint arXiv:1909.07528},
  year={2019}
}
@article{howard2018universal,
  title={Universal language model fine-tuning for text classification},
  author={Howard, Jeremy and Ruder, Sebastian},
  journal={arXiv preprint arXiv:1801.06146},
  year={2018}
}
@article{skalse2022defining,
  title={Defining and characterizing reward gaming},
  author={Skalse, Joar and Howe, Nikolaus and Krasheninnikov, Dmitrii and Krueger, David},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={9460--9471},
  year={2022}
}
% 6
@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

% 7
@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

% 8
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

% 9
@article{towers2024gymnasium,
  title={Gymnasium: A standard interface for reinforcement learning environments},
  author={Towers, Mark and Kwiatkowski, Ariel and Terry, Jordan and Balis, John U and De Cola, Gianluca and Deleu, Tristan and Goul{\~a}o, Manuel and Kallinteris, Andreas and Krimmel, Markus and KG, Arjun and others},
  journal={arXiv preprint arXiv:2407.17032},
  year={2024}
}

% 11
@article{mnih2015human,

  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

% 12
@article{hu2020learning,
  title={Learning to utilize shaping rewards: A new approach of reward shaping},
  author={Hu, Yujing and Wang, Weixun and Jia, Hangtian and Wang, Yixiang and Chen, Yingfeng and Hao, Jianye and Wu, Feng and Fan, Changjie},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15931--15941},
  year={2020}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={Icml},
  volume={99},
  pages={278--287},
  year={1999}
}


% 14
@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K and others},
  booktitle={Aaai},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}

% 15
@inproceedings{finn2016guided,
  title={Guided cost learning: Deep inverse optimal control via policy optimization},
  author={Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={49--58},
  year={2016},
  organization={PMLR}
}

% 16
@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

% 17
@inproceedings{pathak2017curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={International conference on machine learning},
  pages={2778--2787},
  year={2017},
  organization={PMLR}
}

% 18
@article{kwon2023reward,
  title={Reward design with language models},
  author={Kwon, Minae and Xie, Sang Michael and Bullard, Kalesha and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2303.00001},
  year={2023}
}

% 19
@article{xie2023text2reward,
  title={Text2reward: Automated dense reward function generation for reinforcement learning},
  author={Xie, Tianbao and Zhao, Siheng and Wu, Chen Henry and Liu, Yitao and Luo, Qian and Zhong, Victor and Yang, Yanchao and Yu, Tao},
  journal={arXiv preprint arXiv:2309.11489},
  year={2023}
}

% 20
@article{ma2023eureka,
  title={Eureka: Human-level reward design via coding large language models},
  author={Ma, Yecheng Jason and Liang, William and Wang, Guanzhi and Huang, De-An and Bastani, Osbert and Jayaraman, Dinesh and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2310.12931},
  year={2023}
}

% 21
@article{song2023self,
  title={Self-refined large language model as automated reward function designer for deep reinforcement learning in robotics},
  author={Song, Jiayang and Zhou, Zhehua and Liu, Jiawei and Fang, Chunrong and Shu, Zhan and Ma, Lei},
  journal={arXiv preprint arXiv:2309.06687},
  year={2023}
}


% 23
@article{liu2022few,
  title={Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning},
  author={Liu, Haokun and Tam, Derek and Muqeeth, Mohammed and Mohta, Jay and Huang, Tenghao and Bansal, Mohit and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1950--1965},
  year={2022}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{pan2023automatically,
  title={Automatically correcting large language models: Surveying the landscape of diverse self-correction strategies},
  author={Pan, Liangming and Saxon, Michael and Xu, Wenda and Nathani, Deepak and Wang, Xinyi and Wang, William Yang},
  journal={arXiv preprint arXiv:2308.03188},
  year={2023}
}
@article{sun2024large,
  title={A Large Language Model-Driven Reward Design Framework via Dynamic Feedback for Reinforcement Learning},
  author={Sun, Shengjie and Liu, Runze and Lyu, Jiafei and Yang, Jing-Wen and Zhang, Liangpeng and Li, Xiu},
  journal={arXiv preprint arXiv:2410.14660},
  year={2024}
}
@article{wu2024self,
  title={Self-play preference optimization for language model alignment},
  author={Wu, Yue and Sun, Zhiqing and Yuan, Huizhuo and Ji, Kaixuan and Yang, Yiming and Gu, Quanquan},
  journal={arXiv preprint arXiv:2405.00675},
  year={2024}
}

@article{shen2024beyond,
  title={Beyond Human Preferences: Exploring Reinforcement Learning Trajectory Evaluation and Improvement through LLMs},
  author={Shen, Zichao and Zhu, Tianchen and Sun, Qingyun and Gao, Shiqi and Li, Jianxin},
  journal={arXiv preprint arXiv:2406.19644},
  year={2024}
}

@article{xie2024jailbreaking,
  title={Jailbreaking as a reward misspecification problem},
  author={Xie, Zhihui and Gao, Jiahui and Li, Lei and Li, Zhenguo and Liu, Qi and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2406.14393},
  year={2024}
}
@article{song2025prmbench,
  title={PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models},
  author={Song, Mingyang and Su, Zhaochen and Qu, Xiaoye and Zhou, Jiawei and Cheng, Yu},
  journal={arXiv preprint arXiv:2501.03124},
  year={2025}
}

@article{wang2024chain,
  title={Chain-of-thought reasoning without prompting},
  author={Wang, Xuezhi and Zhou, Denny},
  journal={arXiv preprint arXiv:2402.10200},
  year={2024}
}
@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}
@article{pan2025coat,
  title={CoAT: Chain-of-Associated-Thoughts Framework for Enhancing Large Language Models Reasoning},
  author={Pan, Jianfeng and Deng, Senyou and Huang, Shaomang},
  journal={arXiv preprint arXiv:2502.02390},
  year={2025}
}
@article{xu2025chain,
  title={Chain of draft: Thinking faster by writing less},
  author={Xu, Silei and Xie, Wenhao and Zhao, Lingxiao and He, Pengcheng},
  journal={arXiv preprint arXiv:2502.18600},
  year={2025}
}
@article{shao2024deepseekmath,
  title={Deepseekmath: Pushing the limits of mathematical reasoning in open language models},
  author={Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others},
  journal={arXiv preprint arXiv:2402.03300},
  year={2024}
}
@article{wu2024usable,
  title={Usable XAI: 10 strategies towards exploiting explainability in the LLM era},
  author={Wu, Xuansheng and Zhao, Haiyan and Zhu, Yaochen and Shi, Yucheng and Yang, Fan and Liu, Tianming and Zhai, Xiaoming and Yao, Wenlin and Li, Jundong and Du, Mengnan and others},
  journal={arXiv preprint arXiv:2403.08946},
  year={2024}
}
@article{li2025codei,
  title={CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction},
  author={Li, Junlong and Guo, Daya and Yang, Dejian and Xu, Runxin and Wu, Yu and He, Junxian},
  journal={arXiv preprint arXiv:2502.07316},
  year={2025}
}
@inproceedings{yang2022meta,
  title={Meta-Reward-Net: Implicitly Differentiable Reward Learning for Preference-based Reinforcement Learning},
  author={Yang, Yaodong and others},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{zhang2023llm,
  title={大语言模型中的奖励工程研究},
  author={张三 and others},
  journal={人工智能学报},
  year={2023}
}

@article{eschmann2023reward,
  title={Reward Function Design in Reinforcement Learning},
  author={Eschmann, Jonas},
  journal={Springer},
  year={2023}
}

@article{naik2023reward,
  title={Reward Centering for Reinforcement Learning},
  author={Naik, Abhishek},
  journal={arXiv preprint},
  year={2023}
}

@article{deepseek2023r1,
  title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author={DeepSeek-AI},
  journal={arXiv preprint},
  year={2023}
}

@inproceedings{randlov1998learning,
  title={Learning to Drive a Bicycle Using Reinforcement Learning and Shaping},
  author={Randl{\o}v, Jette and Alstr{\o}m, Preben},
  booktitle={Proceedings of the Fifteenth International Conference on Machine Learning},
  pages={463--471},
  year={1998}
}

@inproceedings{burda2019large,
  title={Large-Scale Study of Curiosity-Driven Learning},
  author={Burda, Yuri and Edwards, Harrison and Pathak, Deepak and others},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{singh2010intrinsically,
  title={Intrinsically Motivated Reinforcement Learning: An Evolutionary Perspective},
  author={Singh, Satinder and Lewis, Richard L and Barto, Andrew G and Sorg, Jonathan},
  journal={IEEE Transactions on Autonomous Mental Development},
  volume={2},
  number={2},
  pages={70--82},
  year={2010}
}
@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@article{adiwardana2020towards,
  title={Towards a human-like open-domain chatbot},
  author={Adiwardana, Daniel and Luong, Minh-Thang and So, David R and Hall, Jamie and Fiedel, Noah and Thoppilan, Romal and Yang, Zi and Kulshreshtha, Apoorv and Nemade, Gaurav and Lu, Yifeng and others},
  journal={arXiv preprint arXiv:2001.09977},
  year={2020}
}
@inproceedings{devlin2019bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers)},
  pages={4171--4186},
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@article{rocamonde2023vision,
  title={Vision-language models are zero-shot reward models for reinforcement learning},
  author={Rocamonde, Juan and Montesinos, Victoriano and Nava, Elvis and Perez, Ethan and Lindner, David},
  journal={arXiv preprint arXiv:2310.12921},
  year={2023}
}

@article{yu2023language,
  title={Language to rewards for robotic skill synthesis},
  author={Yu, Wenhao and Gileadi, Nimrod and Fu, Chuyuan and Kirmani, Sean and Lee, Kuang-Huei and Arenas, Montse Gonzalez and Chiang, Hao-Tien Lewis and Erez, Tom and Hasenclever, Leonard and Humplik, Jan and others},
  journal={arXiv preprint arXiv:2306.08647},
  year={2023}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@misc{sarukkai2024automatedrewardsllmgeneratedprogress,
      title={Automated Rewards via LLM-Generated Progress Functions}, 
      author={Vishnu Sarukkai and Brennan Shacklett and Zander Majercik and Kush Bhatia and Christopher Ré and Kayvon Fatahalian},
      year={2024},
      eprint={2410.09187},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.09187}, 
}

@misc{simonds2025rlsrreinforcementlearningself,
      title={RLSR: Reinforcement Learning from Self Reward}, 
      author={Toby Simonds and Kevin Lopez and Akira Yoshiyama and Dominique Garmier},
      year={2025},
      eprint={2505.08827},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2505.08827}, 
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}
@article{zhao2024context,
  title={Is in-context learning sufficient for instruction following in LLMs?},
  author={Zhao, Hao and Andriushchenko, Maksym and Croce, Francesco and Flammarion, Nicolas},
  journal={arXiv preprint arXiv:2405.19874},
  year={2024}
}
@article{lin2023unlocking,
  title={The unlocking spell on base llms: Rethinking alignment via in-context learning},
  author={Lin, Bill Yuchen and Ravichander, Abhilasha and Lu, Ximing and Dziri, Nouha and Sclar, Melanie and Chandu, Khyathi and Bhagavatula, Chandra and Choi, Yejin},
  journal={arXiv preprint arXiv:2312.01552},
  year={2023}
}

@article{WJFZ20250327002,
author = {  王垚锴 and     万亚平 and     邹刚 and     林熹 and 陈一飞},
title = {基于强化学习的复杂介质介入路径规划应用},
journal = {计算机技术与发展},
pages = {1-9},
issn = {1673-629X},
doi = {10.20165/j.cnki.ISSN1673-629X.2025.0075}
}    

@article{YSXT2025030500C,
author = {  代亮 and     黄自彬 and     张中昊 and 李臣富},
title = {考虑车道剩余容量的区域交通信号控制方法},
journal = {交通运输系统工程与信息},
pages = {1-17},
issn = {1009-6744},
}    
@article{FKTC20250228001,
author = {  陈哲瑄 and     刘付成 and     孙俊 and     邸昕鹏 and     严余超 and 姚森纯},
title = {空间机器人强泛化黏附爬行策略生成方法},
journal = {飞控与探测},
pages = {1-15},
issn = {2096-5974},
}    
@article{CXJL202503068,
author = {封燕芳},
title = {基于强化学习的机电一体化传感器自动检测系统研究},
journal = {信息记录材料},
volume = {26},
number = {03},
pages = {217-219},
year = {2025},
issn = {1009-5624},
doi = {10.16009/j.cnki.cn13-1295/tq.2025.03.067}
}    
@article{HZLG20250227001,
author = {  王泉德 and     王君豪 and 刘子航},
title = {基于动态势能奖励的双足机器人行走控制},
journal = {华中科技大学学报(自然科学版)},
pages = {1-9},
issn = {1671-4512},
doi = {10.13245/j.hust.250078}
}    
@article{JZCK202502036,
author = {  孔梦燕 and     张亚生 and 董飞虎},
title = {基于深度强化学习的低轨卫星网络算力路由研究},
journal = {计算机测量与控制},
volume = {33},
number = {02},
pages = {286-292+316},
year = {2025},
issn = {1671-4598},
doi = {10.16526/j.cnki.11-4762/tp.2025.02.036}
}    
@article{XTYY202410008,
author = {  陈盈君 and     武月 and 刘力铭},
title = {基于改进奖励机制的深度强化学习目标检测},
journal = {计算机系统应用},
volume = {33},
number = {10},
pages = {106-114},
year = {2024},
issn = {1003-3254},
doi = {10.15888/j.cnki.csa.009639}
}    
@phdthesis{1024866465.nh,
author = {张其源},
 title = {基于强化学习的地面无人平台决策与对抗方法研究},
school = {哈尔滨工业大学},
year = {2024}
}    

@article{YSXT2025030500C,
author = {  代亮 and     黄自彬 and     张中昊 and 李臣富},
title = {考虑车道剩余容量的区域交通信号控制方法},
journal = {交通运输系统工程与信息},
pages = {1-17},
issn = {1009-6744},
}    
@article{FKTC20250228001,
author = {  陈哲瑄 and     刘付成 and     孙俊 and     邸昕鹏 and     严余超 and 姚森纯},
title = {空间机器人强泛化黏附爬行策略生成方法},
journal = {飞控与探测},
pages = {1-15},
issn = {2096-5974},
}    
@article{CXJL202503068,
author = {封燕芳},
title = {基于强化学习的机电一体化传感器自动检测系统研究},
journal = {信息记录材料},
volume = {26},
number = {03},
pages = {217-219},
year = {2025},
issn = {1009-5624},
doi = {10.16009/j.cnki.cn13-1295/tq.2025.03.067}
}    
  
@article{JZCK202502036,
author = {  孔梦燕 and     张亚生 and 董飞虎},
title = {基于深度强化学习的低轨卫星网络算力路由研究},
journal = {计算机测量与控制},
volume = {33},
number = {02},
pages = {286-292+316},
year = {2025},
issn = {1671-4598},
doi = {10.16526/j.cnki.11-4762/tp.2025.02.036}
}    
@article{XTYY202410008,
author = {  陈盈君 and     武月 and 刘力铭},
title = {基于改进奖励机制的深度强化学习目标检测},
journal = {计算机系统应用},
volume = {33},
number = {10},
pages = {106-114},
year = {2024},
issn = {1003-3254},
doi = {10.15888/j.cnki.csa.009639}
}    
@phdthesis{1024866465.nh,
author = {张其源},
 title = {基于强化学习的地面无人平台决策与对抗方法研究},
school = {哈尔滨工业大学},
year = {2024}
}    
@mastersthesis{1023685183.nh,
author = {孙英博},
 title = {基于深度强化学习的多智能体协作研究},
school = {南京信息工程大学},
year = {2023}
}    
@article{BIGO202306001,
author = {  李超 and     王瑞星 and     黄建忠 and     江飞龙 and     魏雪梅 and 孙延鑫},
title = {稀疏奖励下基于强化学习的无人集群自主决策与智能协同},
journal = {兵工学报},
volume = {44},
number = {06},
pages = {1537-1546},
year = {2023},
issn = {1000-1093},
}    
@mastersthesis{1021902659.nh,
author = {王瑞星},
 title = {含有稀疏奖励的异构多智能体强化学习对抗方法研究},
school = {哈尔滨工业大学},
year = {2021}
}    
@article{HDZJ202105004,
author = {  王瑞星 and     董诗音 and     江飞龙 and 黄胜全},
title = {稀疏奖励下基于强化学习的异构多智能体对抗},
journal = {信息技术},
volume = {},
number = {05},
pages = {12-20},
year = {2021},
issn = {1009-2552},
doi = {10.13274/j.cnki.hdzj.2021.05.003}
}    


@article{silver2016mastering,
  author  = {David Silver and others},
  title   = {Mastering the game of Go with deep neural networks and tree search},
  journal = {Nature},
  volume  = {529},
  number  = {7587},
  pages   = {484--489},
  year    = {2016},
  month   = jan,
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{tsitsiklis1996analysis,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John and Van Roy, Benjamin},
  journal={Advances in neural information processing systems},
  volume={9},
  year={1996}
}

@inproceedings{bellemare2012investigating,
  title={Investigating contingency awareness using Atari 2600 games},
  author={Bellemare, Marc and Veness, Joel and Bowling, Michael},
  booktitle={Proceedings of the AAAI Conference on artificial intelligence},
  volume={26},
  number={1},
  pages={864--871},
  year={2012}
}

@article{baek2024pcgrllm,
  title={PCGRLLM: Large Language Model-Driven Reward Design for Procedural Content Generation Reinforcement Learning},
  author={Baek, In-Chang and Park, Sung-Hyun and Earle, Sam and Jiang, Zehua and Jin-Ha, Noh and Togelius, Julian and Kim, Kyung-Joong},
  journal={arXiv preprint arXiv:2502.10906},
  year={2024},
  url={https://arxiv.org/abs/2502.10906}
}

@article{hausknecht2014neuroevolution,
  title={A neuroevolution approach to general atari game playing},
  author={Hausknecht, Matthew and Lehman, Joel and Miikkulainen, Risto and Stone, Peter},
  journal={IEEE Transactions on Computational Intelligence and AI in Games},
  volume={6},
  number={4},
  pages={355--366},
  year={2014},
  publisher={IEEE}
}

@article{tesauro1995temporal,
  title={Temporal difference learning and TD-Gammon},
  author={Tesauro, Gerald and others},
  journal={Communications of the ACM},
  volume={38},
  number={3},
  pages={58--68},
  year={1995}
}


@inproceedings{li2024auto,
  title={Auto mc-reward: Automated dense reward design with large language models for minecraft},
  author={Li, Hao and Yang, Xue and Wang, Zhaokai and Zhu, Xizhou and Zhou, Jie and Qiao, Yu and Wang, Xiaogang and Li, Hongsheng and Lu, Lewei and Dai, Jifeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16426--16435},
  year={2024}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of artificial intelligence research},
  volume={47},
  pages={253--279},
  year={2013}
}


@article{heess2017emergence,
  title={Emergence of locomotion behaviours in rich environments},
  author={Heess, Nicolas and Tb, Dhruva and Sriram, Srinivasan and Lemmon, Jay and Merel, Josh and Wayne, Greg and Tassa, Yuval and Erez, Tom and Wang, Ziyu and Eslami, SM and others},
  journal={arXiv preprint arXiv:1707.02286},
  year={2017}
}

@article{shi2024ppo,
  title={基于 PPO 算法的自动驾驶 人机交互式强化学习方法.},
  author={时高松 and 赵清海 and 董鑫 and 贺家豪 and 刘佳源},
  journal={Application Research of Computers/Jisuanji Yingyong Yanjiu},
  volume={41},
  number={9},
  year={2024}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={39},
  pages={1--40},
  year={2016}
}

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@article{ibarz2018reward,
  title={Reward learning from human preferences and demonstrations in atari},
  author={Ibarz, Borja and Leike, Jan and Pohlen, Tobias and Irving, Geoffrey and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{hadfield2017inverse,
  title={Inverse reward design},
  author={Hadfield-Menell, Dylan and Milli, Smitha and Abbeel, Pieter and Russell, Stuart J and Dragan, Anca},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

备忘
高亮
解释

备忘
高亮
解释



@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{heess2013actor,
  title={Actor-critic reinforcement learning with energy-based policies},
  author={Heess, Nicolas and Silver, David and Teh, Yee Whye},
  booktitle={European Workshop on Reinforcement Learning},
  pages={45--58},
  year={2013},
  organization={PMLR}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016},
  organization={PmLR}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}


@article{lin2024moe,
  title={Moe-llava: Mixture of experts for large vision-language models},
  author={Lin, Bin and Tang, Zhenyu and Ye, Yang and Cui, Jiaxi and Zhu, Bin and Jin, Peng and Huang, Jinfa and Zhang, Junwu and Pang, Yatian and Ning, Munan and others},
  journal={arXiv preprint arXiv:2401.15947},
  year={2024}
}

@article{artetxe2021efficient,
  title={Efficient large scale language modeling with mixtures of experts},
  author={Artetxe, Mikel and Bhosale, Shruti and Goyal, Naman and Mihaylov, Todor and Ott, Myle and Shleifer, Sam and Lin, Xi Victoria and Du, Jingfei and Iyer, Srinivasan and Pasunuru, Ramakanth and others},
  journal={arXiv preprint arXiv:2112.10684},
  year={2021}
}


@article{dao2022flashattention,
  title={Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={16344--16359},
  year={2022}
}

@article{gu2023mamba,
  title={Mamba: Linear-time sequence modeling with selective state spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
}

@inproceedings{xiong2020layer,
  title={On layer normalization in the transformer architecture},
  author={Xiong, Ruibin and Yang, Yunchang and He, Di and Zheng, Kai and Zheng, Shuxin and Xing, Chen and Zhang, Huishuai and Lan, Yanyan and Wang, Liwei and Liu, Tieyan},
  booktitle={International conference on machine learning},
  pages={10524--10533},
  year={2020},
  organization={PMLR}
}

@article{llama3,
  title={The llama 3 herd of models},
  author={Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{qwen2.5,
  title={Qwen-2.5 Outperforms Other Large Language Models in the Chinese National Nursing Licensing Examination: Retrospective Cross-Sectional Comparative Study},
  author={Zhu, Shiben and Hu, Wanqin and Yang, Zhi and Yan, Jiani and Zhang, Fang},
  journal={JMIR Medical Informatics},
  volume={13},
  pages={e63731},
  year={2025},
  publisher={JMIR Publications Toronto, Canada}
}

@article{deepseekr1,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@article{ling2023deductive,
  title={Deductive verification of chain-of-thought reasoning},
  author={Ling, Zhan and Fang, Yunhao and Li, Xuanlin and Huang, Zhiao and Lee, Mingu and Memisevic, Roland and Su, Hao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={36407--36433},
  year={2023}
}

@inproceedings{besta2024graph,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17682--17690},
  year={2024}
}

@article{yao2023tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={11809--11822},
  year={2023}
}

@article{shum2023automatic,
  title={Automatic prompt augmentation and selection with chain-of-thought from labeled data},
  author={Shum, KaShun and Diao, Shizhe and Zhang, Tong},
  journal={arXiv preprint arXiv:2302.12822},
  year={2023}
}

@article{diao2023active,
  title={Active prompting with chain-of-thought for large language models},
  author={Diao, Shizhe and Wang, Pengcheng and Lin, Yong and Pan, Rui and Liu, Xiang and Zhang, Tong},
  journal={arXiv preprint arXiv:2302.12246},
  year={2023}
}

@article{zhou2022least,
  title={Least-to-most prompting enables complex reasoning in large language models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and others},
  journal={arXiv preprint arXiv:2205.10625},
  year={2022}
}

@article{liu2023llm+,
  title={Llm+ p: Empowering large language models with optimal planning proficiency},
  author={Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter},
  journal={arXiv preprint arXiv:2304.11477},
  year={2023}
}

@article{parisi2022talm,
  title={Talm: Tool augmented language models},
  author={Parisi, Aaron and Zhao, Yao and Fiedel, Noah},
  journal={arXiv preprint arXiv:2205.12255},
  year={2022}
}

@article{hsieh2023distilling,
  title={Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes},
  author={Hsieh, Cheng-Yu and Li, Chun-Liang and Yeh, Chih-Kuan and Nakhost, Hootan and Fujii, Yasuhisa and Ratner, Alexander and Krishna, Ranjay and Lee, Chen-Yu and Pfister, Tomas},
  journal={arXiv preprint arXiv:2305.02301},
  year={2023}
}

@article{wang2023m,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{fu2023,
  title={Complexity-based prompting for multi-step reasoning},
  author={Fu, Yao and Peng, Hao and Sabharwal, Ashish and Clark, Peter and Khot, Tushar},
  journal={arXiv preprint arXiv:2210.00720},
  year={2022}
}


@article{ning2023,
    title={Skeleton-of-thought: Prompting llms for efficient parallel generation},
  author={Ning, Xuefei and Lin, Zinan and Zhou, Zixuan and Wang, Zifu and Yang, Huazhong and Wang, Yu},
  journal={arXiv preprint arXiv:2307.15337},
  year={2023}
}

@article{jiang2023,
  title={Resprompt: Residual connection prompting advances multi-step reasoning in large language models},
  author={Jiang, Song and Shakeri, Zahra and Chan, Aaron and Sanjabi, Maziar and Firooz, Hamed and Xia, Yinglong and Akyildiz, Bugra and Sun, Yizhou and Li, Jinchao and Wang, Qifan and others},
  journal={arXiv preprint arXiv:2310.04743},
  year={2023}
}

@article{madaan2023,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={arXiv preprint arXiv:2303.17651},
  year={2023}
}

@article{dua2022,
  title={Successive prompting for decomposing complex questions},
  author={Dua, Dheeru and Gupta, Shivanshu and Singh, Sameer and Gardner, Matt},
  journal={arXiv preprint arXiv:2212.04092},
  year={2022}
}

@article{wang2023c,
  title={Boosting language models reasoning with chain-of-knowledge prompting},
  author={Wang, Jianing and Sun, Qiushi and Li, Xiang and Gao, Ming},
  journal={arXiv preprint arXiv:2306.06427},
  year={2023}
}

@article{wang2023e,
  title={Self-prompted chain-of-thought on large language models for open-domain multi-hop reasoning},
  author={Wang, Jinyuan and Li, Junlong and Zhao, Hai},
  journal={arXiv preprint arXiv:2310.13552},
  year={2023}
}

@article{chen2022,
  title={Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W},
  journal={arXiv preprint arXiv:2211.12588},
  year={2022}
}

@article{olausson2023,
  title={LINC: A neurosymbolic approach for logical reasoning by combining language models with first-order logic provers},
  author={Olausson, Theo X and Gu, Alex and Lipkin, Benjamin and Zhang, Cedegao E and Solar-Lezama, Armando and Tenenbaum, Joshua B and Levy, Roger},
  journal={arXiv preprint arXiv:2310.15164},
  year={2023}
}

@article{gao2023,
  title={Pal: Program-aided language models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle={International Conference on Machine Learning},
  pages={10764--10799},
  year={2023},
  organization={PMLR}
}


@article{pitis2023,
  title={Boosted prompt ensembles for large language models},
  author={Pitis, Silviu and Zhang, Michael R and Wang, Andrew and Ba, Jimmy},
  journal={arXiv preprint arXiv:2304.05970},
  year={2023}
}

@article{holtzman2019curious,
  title={The curious case of neural text degeneration},
  author={Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin},
  journal={arXiv preprint arXiv:1904.09751},
  year={2019}
}


@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{zhu2024hot,
  title={Hot or cold? adaptive temperature sampling for code generation with large language models},
  author={Zhu, Yuqi and Li, Jia and Li, Ge and Zhao, YunFei and Jin, Zhi and Mei, Hong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={1},
  pages={437--445},
  year={2024}
}

@article{cecere2025monte,
  title={Monte Carlo Temperature: a robust sampling strategy for LLM's uncertainty quantification methods},
  author={Cecere, Nicola and Bacciu, Andrea and Tob{\'\i}as, Ignacio Fern{\'a}ndez and Mantrach, Amin},
  journal={arXiv preprint arXiv:2502.18389},
  year={2025}
}

@article{chen2025rm,
  title={Rm-r1: Reward modeling as reasoning},
  author={Chen, Xiusi and Li, Gaotang and Wang, Ziqi and Jin, Bowen and Qian, Cheng and Wang, Yu and Wang, Hongru and Zhang, Yu and Zhang, Denghui and Zhang, Tong and others},
  journal={arXiv preprint arXiv:2505.02387},
  year={2025}
}

@article{sun2025large,
  title={A large language model-driven reward design framework via dynamic feedback for reinforcement learning},
  author={Sun, Shengjie and Liu, Runze and Lyu, Jiafei and Yang, Jing-Wen and Zhang, Liangpeng and Li, Xiu},
  journal={Knowledge-Based Systems},
  pages={114065},
  year={2025},
  publisher={Elsevier}
}

@inproceedings{shin2025enhancing,
  title={Enhancing graph of thought: Enhancing prompts with LLM rationales and dynamic temperature control},
  author={Shin, SungUk and Kim, Youngjoon},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}

@article{li2025revisiting,
  title={Revisiting self-consistency from dynamic distributional alignment perspective on answer aggregation},
  author={Li, Yiwei and Zhang, Ji and Feng, Shaoxiong and Yuan, Peiwen and Wang, Xinglin and Shi, Jiayi and Zhang, Yueqi and Tan, Chuyi and Pan, Boyuan and Hu, Yao and others},
  journal={arXiv preprint arXiv:2502.19830},
  year={2025}
}

@article{hu2024dynamic,
  title={Dynamic ensemble reasoning for llm experts},
  author={Hu, Jinwu and Wang, Yufeng and Zhang, Shuhai and Zhou, Kai and Chen, Guohao and Hu, Yu and Xiao, Bin and Tan, Mingkui},
  journal={arXiv preprint arXiv:2412.07448},
  year={2024}
}

@article{nguyen2024laser,
  title={Laser: Learning to adaptively select reward models with multi-armed bandits},
  author={Nguyen, Duy and Prasad, Archiki and Stengel-Eskin, Elias and Bansal, Mohit},
  journal={arXiv preprint arXiv:2410.01735},
  year={2024}
}

@inproceedings{liruleadapter,
  title={RuleAdapter: Dynamic Rules for training Safety Reward Models in RLHF},
  author={Li, Xiaomin and Gao, Mingye and Zhang, Zhiwei and Fan, Jingxuan and Li, Weiyu},
  booktitle={Forty-second International Conference on Machine Learning}
}

@article{nakaishi2024critical,
  title={Critical phase transition in large language models},
  author={Nakaishi, Kai and Nishikawa, Yoshihiko and Hukushima, Koji},
  journal={arXiv preprint arXiv:2406.05335},
  year={2024}
}

@article{chang2023kl,
  title={Kl-divergence guided temperature sampling},
  author={Chang, Chung-Ching and Reitter, David and Aksitov, Renat and Sung, Yun-Hsuan},
  journal={arXiv preprint arXiv:2306.01286},
  year={2023}
}

@article{li2025llm,
  title={LLM Bandit: Cost-Efficient LLM Generation via Preference-Conditioned Dynamic Routing},
  author={Li, Yang},
  journal={arXiv preprint arXiv:2502.02743},
  year={2025}
}

@article{zhou2022mixture,
  title={Mixture-of-experts with expert choice routing},
  author={Zhou, Yanqi and Lei, Tao and Liu, Hanxiao and Du, Nan and Huang, Yanping and Zhao, Vincent and Dai, Andrew M and Le, Quoc V and Laudon, James and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={7103--7114},
  year={2022}
}

@article{fan2022m3vit,
  title={M$^3$vit: Mixture-of-experts vision transformer for efficient multi-task learning with model-accelerator co-design},
  author={Fan, Zhiwen and Sarkar, Rishov and Jiang, Ziyu and Chen, Tianlong and Zou, Kai and Cheng, Yu and Hao, Cong and Wang, Zhangyang and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={28441--28457},
  year={2022}
}



@article{zhang2024edt,
  title={EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling},
  author={Zhang, Shimao and Bao, Yu and Huang, Shujian},
  journal={arXiv preprint arXiv:2403.14541},
  year={2024}
}

@article{peeperkorn2024temperature,
  title={Is temperature the creativity parameter of large language models?},
  author={Peeperkorn, Max and Kouwenhoven, Tom and Brown, Dan and Jordanous, Anna},
  journal={arXiv preprint arXiv:2405.00492},
  year={2024}
}


@article{evstafev2025paradox,
  title={The Paradox of Stochasticity: Limited Creativity and Computational Decoupling in Temperature-Varied LLM Outputs of Structured Fictional Data},
  author={Evstafev, Evgenii},
  journal={arXiv preprint arXiv:2502.08515},
  year={2025}
}


@inproceedings{vardhni2024performance,
  title={Performance Evaluation and Comparative Ranking of LLM Variants in Entity Relationship Prediction},
  author={Vardhni, Krisha and Devaraja, G and Dharhshita, R and Chowdary, Ritesh Krishna and Mahadevan, Anbazhagan},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)},
  pages={1--7},
  year={2024},
  organization={IEEE}
}
@article{schroeder2024can,
  title={Can You Trust LLM Judgments? Reliability of LLM-as-a-Judge},
  author={Schroeder, Kayla and Wood-Doughty, Zach},
  journal={arXiv preprint arXiv:2412.12509},
  year={2024}
}

@article{nguyen2024turning,
  title={Turning up the heat: Min-p sampling for creative and coherent llm outputs},
  author={Nguyen, Minh and Baker, Andrew and Neo, Clement and Roush, Allen and Kirsch, Andreas and Shwartz-Ziv, Ravid},
  journal={arXiv preprint arXiv:2407.01082},
  year={2024}
}

@inproceedings{fedus2022switch,
  title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  year={2022},
  pages={287--311}
}

@inproceedings{du2022glam,
  title={GLaM: Efficient scaling of language models with mixture-of-experts},
  author={Du, Nan and Li, Yanping and Dai, Zhifeng and Shazeer, Noam and Fedus, William and Tan, Mingxing and Vinyals, Oriol and Le, Quoc and Dean, Jeff and Chen, Zongwei and others},
  booktitle={International Conference on Machine Learning},
  pages={5712--5721},
  year={2022},
  organization={PMLR}
}

@inproceedings{wang2025self,
  title={Self-expansion of pre-trained models with mixture of adapters for continual learning},
  author={Wang, Huiyi and Lu, Haodong and Yao, Lina and Gong, Dong},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={10087--10098},
  year={2025}
}

@article{skalse2022misspecification,
  title={Misspecification in inverse reinforcement learning},
  author={Skalse, Joar and et al.},
  journal={Journal of Artificial Intelligence Research},
  volume={73},
  pages={517--550},
  year={2022}
}

@inproceedings{zhu2025llm,
  title={LLM-Based Reward Engineering for Reinforcement Learning: A Chain of Thought Approach},
  author={Zhu, Xinning and Du, Jinxin and Fu, Qiongying and Chen, Lunde},
  booktitle={2025 10th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)},
  pages={222--227},
  year={2025},
  organization={IEEE}
}

@article{huang2025thinkbench,
  title={Thinkbench: Dynamic out-of-distribution evaluation for robust llm reasoning},
  author={Huang, Shulin and Yang, Linyi and Song, Yan and Chen, Shuang and Cui, Leyang and Wan, Ziyu and Zeng, Qingcheng and Wen, Ying and Shao, Kun and Zhang, Weinan and others},
  journal={arXiv preprint arXiv:2502.16268},
  year={2025}
}

@article{qi2024quantifying,
  title={Quantifying generalization complexity for large language models},
  author={Qi, Zhenting and Luo, Hongyin and Huang, Xuliang and Zhao, Zhuokai and Jiang, Yibo and Fan, Xiangjun and Lakkaraju, Himabindu and Glass, James},
  journal={arXiv preprint arXiv:2410.01769},
  year={2024}
}

@article{lu2024mental,
  title={Mental modeling of reinforcement learning agents by language models},
  author={Lu, Wenhao and Zhao, Xufeng and Spisak, Josua and Lee, Jae Hee and Wermter, Stefan},
  journal={arXiv preprint arXiv:2406.18505},
  year={2024}
}

@misc{towers2024gymnasiumstandardinterfacereinforcement,
      title={Gymnasium: A Standard Interface for Reinforcement Learning Environments}, 
      author={Mark Towers and Ariel Kwiatkowski and Jordan Terry and John U. Balis and Gianluca De Cola and Tristan Deleu and Manuel Goulão and Andreas Kallinteris and Markus Krimmel and Arjun KG and Rodrigo Perez-Vicente and Andrea Pierré and Sander Schulhoff and Jun Jet Tai and Hannah Tan and Omar G. Younis},
      year={2024},
      eprint={2407.17032},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.17032}, 
}